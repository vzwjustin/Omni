# Omni-Cortex: AI Thinking Frameworks MCP Server

An MCP (Model Context Protocol) server that provides 40 advanced reasoning frameworks for AI assistants. Built with LangGraph for orchestration and LangChain for memory/RAG capabilities.

## Overview

Omni-Cortex is a **simple MCP server** that provides 40 specialized reasoning framework prompt templates. Each framework is exposed as an MCP tool that returns structured prompts for the calling AI to execute.

**Key Architecture:**
- **Prompt Templates**: Each framework returns a structured prompt template
- **Smart Routing**: Auto-selects best framework based on task keywords
- **No API Keys Required**: Server just returns prompts, calling LLM does all reasoning
- **Optional Utilities**: Memory persistence, RAG search, code execution tools available

**How it works:**
1. Your AI (Claude Code, Cursor, Windsurf, etc.) calls a framework tool (e.g., `think_active_inference`)
2. MCP server returns a structured prompt template with the framework's approach
3. Your AI receives the prompt and performs the actual reasoning
4. Simple, fast, no external API calls needed!

## ğŸ§  Available Frameworks (40 Total)

### Strategy (7 frameworks)
- **ReasonFlux** - Hierarchical planning: Template â†’ Expand â†’ Refine
- **Self-Discover** - Discover and compose custom reasoning patterns
- **Buffer of Thoughts** - Build context in a thought buffer
- **CoALA** - Cognitive architecture with memory systems
- **Least-to-Most** - Bottom-up atomic function decomposition
- **Comparative Architecture** - Multiple solution approaches (readability/memory/speed)
- **Plan-and-Solve** - Explicit planning before execution

### Search (4 frameworks)
- **rStar-Code MCTS** - Monte Carlo Tree Search for code exploration
- **Tree of Thoughts** - Explore multiple solution paths, pick best
- **Graph of Thoughts** - Non-linear reasoning with idea graphs
- **Everything of Thought** - Combine multiple reasoning approaches

### Iterative (8 frameworks)
- **Active Inference** - Hypothesis testing loop for debugging
- **Multi-Agent Debate** - Multiple perspectives argue trade-offs
- **Adaptive Injection** - Inject strategies as needed
- **RE2** - Read-Execute-Evaluate loop for requirements
- **Rubber Duck Debugging** - Socratic questioning for self-discovery
- **ReAct** - Interleaved reasoning and acting with tools
- **Reflexion** - Self-evaluation with memory-based learning
- **Self-Refine** - Iterative self-critique and improvement

### Code (13 frameworks)
- **Program of Thoughts** - Generate executable code to solve problems
- **Chain of Verification** - Draft â†’ Verify â†’ Patch cycle
- **CRITIC** - Generate then critique with external validation
- **Chain-of-Code** - Break problems into code blocks for structured thinking
- **Self-Debugging** - Mental execution trace before presenting code
- **TDD Prompting** - Write tests first, then implementation
- **Reverse Chain-of-Thought** - Work backward from buggy output to source
- **AlphaCodium** - Test-based multi-stage iterative code generation (competitive programming)
- **CodeChain** - Chain of self-revisions guided by sub-modules
- **Evol-Instruct** - Evolutionary instruction complexity with constraints
- **LLMLOOP** - Automated iterative feedback loops (compilation, tests, mutation)
- **ProCoder** - Compiler-feedback-guided iterative refinement
- **RECODE** - Multi-candidate validation with CFG-based debugging

### Context (6 frameworks)
- **Chain of Note** - Research and note-taking approach
- **Step-Back** - Abstract principles first, then apply
- **Analogical** - Find and adapt similar solutions
- **Red-Teaming** - Adversarial security analysis (STRIDE, OWASP)
- **State-Machine Reasoning** - Formal FSM design before coding
- **Chain-of-Thought** - Basic step-by-step reasoning

### Fast (2 frameworks)
- **Skeleton of Thought** - Outline first, fill in details
- **System1** - Quick intuitive responses

## ğŸ¯ Key Features

- **Smart Routing**: Auto-selects optimal framework based on task analysis
- **Vibe Dictionary**: Natural language activation ("wtf is broken" â†’ Active Inference)
- **Memory Systems**: LangChain-powered conversation history and framework tracking
- **RAG Integration**: ChromaDB vector store with 6 specialized collections
- **Tool Integration**: Execute code, search docs, retrieve context
- **Quiet-STaR**: Internal thought processes for enhanced reasoning

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MCP Client (Claude Code/Cursor/Windsurf)         â”‚
â”‚  â€¢ Calls framework tool (e.g., think_active_inference)â”‚
â”‚  â€¢ Receives prompt template                          â”‚
â”‚  â€¢ Performs actual reasoning                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ MCP Protocol
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Omni-Cortex MCP Server                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  55 MCP Tools                               â”‚     â”‚
â”‚  â”‚  â€¢ 40 think_* framework tools               â”‚     â”‚
â”‚  â”‚  â€¢ 1 reason (smart routing)                 â”‚     â”‚
â”‚  â”‚  â€¢ 14 utility tools (search, memory, etc)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                   â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Framework Templates (FRAMEWORKS dict)      â”‚     â”‚
â”‚  â”‚  â€¢ 40 prompt templates                      â”‚     â”‚
â”‚  â”‚  â€¢ Each with category, description          â”‚     â”‚
â”‚  â”‚  â€¢ Best-for use cases                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                   â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Simple Router (for "reason" tool)          â”‚     â”‚
â”‚  â”‚  â€¢ Vibe Dictionary (keyword matching)       â”‚     â”‚
â”‚  â”‚  â€¢ Heuristic selection                      â”‚     â”‚
â”‚  â”‚  â€¢ Returns selected framework template      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                   â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Optional Utilities                         â”‚     â”‚
â”‚  â”‚  â€¢ Memory (LangChain conversation history)  â”‚     â”‚
â”‚  â”‚  â€¢ RAG (ChromaDB vector search)             â”‚     â”‚
â”‚  â”‚  â€¢ Code execution                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Returns prompt template
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     MCP Client executes the framework's approach     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Prerequisites
- Python 3.11+
- **No API keys required!** (Server just returns prompt templates)
- Optional: API keys for RAG/embeddings features (if you want to use the optional search tools)

### Setup

```bash
# Clone the repository
git clone <repository-url>
cd thinking-frameworks/omni_cortex

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Optional Environment Variables

Only needed if you want to use the optional RAG search tools:

```bash
# Optional (for RAG search tools only)
OPENAI_API_KEY=sk-...              # For embeddings/vector search
# OR
OPENROUTER_API_KEY=sk-or-...       # Alternative for embeddings

# Optional settings
CHROMA_PERSIST_DIR=/app/data/chroma  # Vector store location
LOG_LEVEL=INFO                     # Logging level
```

## ğŸš€ Usage

### Running the MCP Server

```bash
# From omni_cortex directory
python -m server.main
```

The server runs via stdio and communicates using the MCP protocol.

### MCP Configuration

Add to your Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS):

```json
{
  "mcpServers": {
    "omni-cortex": {
      "command": "python",
      "args": ["-m", "server.main"],
      "cwd": "/path/to/thinking-frameworks/omni_cortex"
    }
  }
}
```

No API keys needed! The server just returns prompt templates.

### Using in Claude Code / Cursor / Windsurf

Once configured, the framework tools are available:

```
# Auto-select framework
Use the "reason" tool with your query
â†’ Server analyzes your query
â†’ Selects best framework (e.g., active_inference for debugging)
â†’ Returns the framework's prompt template
â†’ Your AI applies the framework's reasoning approach

# Or explicitly select a framework
Use "think_active_inference" for debugging
â†’ Returns Active Inference prompt template (hypothesis testing loop)

Use "think_alphacodium" for competitive programming
â†’ Returns AlphaCodium template (test-based iterative approach)

Use "think_chain_of_verification" for security review
â†’ Returns verification framework (draft â†’ verify â†’ patch)

# What you get back:
â†’ Structured prompt with the framework's methodology
â†’ Framework description and best use cases
â†’ Your AI then executes the reasoning following that structure
```

### Ingesting Documentation for RAG

```bash
# Ingest repository files into vector store
python -m app.ingest_repo

# For enhanced ingestion with metadata
python -m app.enhanced_ingestion
```

## ğŸ› ï¸ Development

### Project Structure

```
omni_cortex/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Settings and configuration
â”‚   â”‚   â””â”€â”€ router.py          # HyperRouter for framework selection
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ strategy/          # Strategic planning frameworks (7)
â”‚   â”‚   â”œâ”€â”€ search/            # Tree/graph search frameworks (4)
â”‚   â”‚   â”œâ”€â”€ iterative/         # Iterative refinement frameworks (8)
â”‚   â”‚   â”œâ”€â”€ code/              # Code-focused frameworks (13)
â”‚   â”‚   â”‚   â”œâ”€â”€ pot.py         # Program of Thoughts
â”‚   â”‚   â”‚   â”œâ”€â”€ alphacodium.py # Test-based multi-stage (NEW)
â”‚   â”‚   â”‚   â”œâ”€â”€ codechain.py   # Sub-module self-revision (NEW)
â”‚   â”‚   â”‚   â”œâ”€â”€ evol_instruct.py # Evolutionary complexity (NEW)
â”‚   â”‚   â”‚   â”œâ”€â”€ llmloop.py     # 5-loop refinement (NEW)
â”‚   â”‚   â”‚   â”œâ”€â”€ procoder.py    # Compiler-guided (NEW)
â”‚   â”‚   â”‚   â””â”€â”€ recode.py      # Multi-candidate CFG (NEW)
â”‚   â”‚   â”œâ”€â”€ context/           # Context-building frameworks (6)
â”‚   â”‚   â”œâ”€â”€ fast/              # Quick response frameworks (2)
â”‚   â”‚   â”œâ”€â”€ common.py          # Shared utilities (@quiet_star decorator)
â”‚   â”‚   â””â”€â”€ langchain_tools.py # Tool integration
â”‚   â”œâ”€â”€ graph.py               # LangGraph workflow (routeâ†’execute nodes)
â”‚   â”œâ”€â”€ state.py               # GraphState management
â”‚   â”œâ”€â”€ langchain_integration.py  # Memory, RAG, callbacks
â”‚   â”œâ”€â”€ collection_manager.py  # Multi-collection vector store
â”‚   â””â”€â”€ schemas.py             # Pydantic models
â”œâ”€â”€ server/
â”‚   â””â”€â”€ main.py                # MCP server (wired to graph.ainvoke)
â””â”€â”€ mcp-config-examples/       # Example configurations
```

### Adding a New Framework

1. **Create node implementation**: `app/nodes/category/my_framework.py`
   ```python
   from ...state import GraphState
   from ..common import quiet_star, add_reasoning_step, format_code_context

   @quiet_star
   async def my_framework_node(state: GraphState) -> GraphState:
       # Your framework logic here
       state["final_answer"] = "..."
       state["confidence_score"] = 0.85
       return state
   ```

2. **Export from category**: Add to `app/nodes/category/__init__.py`
   ```python
   from .my_framework import my_framework_node
   __all__ = [..., "my_framework_node"]
   ```

3. **Register in graph**: Add to `app/graph.py` FRAMEWORK_NODES dict
   ```python
   from .nodes.category import my_framework_node
   FRAMEWORK_NODES = {
       "my_framework": my_framework_node,
   }
   ```

4. **Add MCP tool definition**: Update `server/main.py` FRAMEWORKS dict
   ```python
   FRAMEWORKS = {
       "my_framework": {
           "category": "code",
           "description": "Brief description",
           "best_for": ["use case 1", "use case 2"],
           "prompt": """Framework prompt template..."""
       }
   }
   ```

5. **Update router vibes** (optional): Add to `app/core/router.py` VIBE_DICTIONARY
   ```python
   VIBE_DICTIONARY = {
       "my_framework": ["keyword1", "keyword2", "phrase"],
   }
   ```

All execution automatically flows through LangGraph - no additional wiring needed!

## ğŸ“Š Collections (RAG)

The system maintains 6 specialized ChromaDB collections:

- **frameworks** - Framework implementations and reasoning nodes
- **documentation** - Markdown docs, READMEs, guides
- **configs** - Configuration files
- **utilities** - Helper functions
- **tests** - Test files
- **integrations** - LangChain/LangGraph integration code

## ğŸ”§ Configuration

Key settings in `app/core/config.py`:

```python
max_reasoning_depth: int = 10        # Max recursion depth
mcts_max_rollouts: int = 50          # MCTS exploration limit
debate_max_rounds: int = 5           # Multi-agent debate rounds
enable_prm_scoring: bool = True      # Process Reward Model
enable_dspy_optimization: bool = True # Prompt optimization
```

## ğŸ§ª Testing

```bash
# Run tests
pytest

# Run specific test
pytest tests/test_router.py

# With coverage
pytest --cov=app tests/
```

## ğŸ“ Example Use Cases

All examples execute through full LangGraph orchestration:

- **Debugging**: "Why is this throwing a null pointer?" â†’ Active Inference (hypothesis testing loop)
- **Architecture**: "Design a REST API for user management" â†’ ReasonFlux (hierarchical planning)
- **Competitive Programming**: "Solve this LeetCode hard problem" â†’ AlphaCodium (test-based iterative)
- **Production Code**: "Generate production-ready user auth" â†’ LLMLOOP (5-loop refinement)
- **Large Codebase Integration**: "Add this feature to existing system" â†’ ProCoder (compiler-guided)
- **High-Stakes Code**: "Generate critical payment processing logic" â†’ RECODE (multi-candidate validation)
- **Security**: "Audit this code for vulnerabilities" â†’ Chain of Verification + Red-Teaming
- **Math**: "Calculate the optimal portfolio allocation" â†’ Program of Thoughts
- **Research**: "Understand how this codebase works" â†’ Chain of Note

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

## ğŸ“„ License

[Add your license here]

## ğŸ™ Acknowledgments

Built with:
- [MCP](https://modelcontextprotocol.io/) - Model Context Protocol
- [LangGraph](https://github.com/langchain-ai/langgraph) - Graph-based LLM orchestration
- [LangChain](https://github.com/langchain-ai/langchain) - LLM application framework
- [ChromaDB](https://www.trychroma.com/) - Vector database

Inspired by research in:
- Tree of Thoughts, Graph of Thoughts, Buffer of Thoughts
- rStar-Code (MCTS for code)
- Active Inference for debugging
- Self-Discover, CoALA, and other reasoning frameworks
