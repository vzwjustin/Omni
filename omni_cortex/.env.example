# Omni-Cortex Configuration
# Pass-through mode - calling LLM does the reasoning

# =============================================================================
# MODE
# =============================================================================
# pass-through: MCP returns prompts, calling LLM executes
LLM_PROVIDER=pass-through

# =============================================================================
# EMBEDDINGS (for ChromaDB / RAG)
# =============================================================================
# OpenAI API key for text-embedding-3-large
# Required for RAG/search features
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# CHROMADB STORAGE
# =============================================================================
CHROMA_PERSIST_DIR=/app/data/chroma

# =============================================================================
# FEATURE FLAGS
# =============================================================================
# Automatically ingest repo into Chroma at startup
ENABLE_AUTO_INGEST=true

# DSPy-style prompt optimization
ENABLE_DSPY_OPTIMIZATION=true

# Process Reward Model for scoring reasoning steps
ENABLE_PRM_SCORING=true

# =============================================================================
# LIMITS & TUNING
# =============================================================================
# Maximum depth for recursive reasoning frameworks
MAX_REASONING_DEPTH=10

# MCTS maximum rollouts per search
MCTS_MAX_ROLLOUTS=50

# Multi-agent debate maximum rounds
DEBATE_MAX_ROUNDS=5

# =============================================================================
# LOGGING
# =============================================================================
LOG_LEVEL=INFO
